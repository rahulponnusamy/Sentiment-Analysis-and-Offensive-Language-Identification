{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_and_NN_for_tam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdbxAM5VEc8-"
      },
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTmKTgSeeuQ"
      },
      "source": [
        "#importing required libaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import string\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkpCVt-IEhxb"
      },
      "source": [
        "**Tamil Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg7J-VrzfTBD"
      },
      "source": [
        "#reading the Tamil dataset\n",
        "train=pd.read_csv('/content/drive/MyDrive/offensive language/Tamil dataset/Tamil-Codemixed_offensive_Training-Tweet.tsv',sep='\\t', index_col=[0])\n",
        "test=pd.read_csv('/content/drive/MyDrive/offensive language/Tamil dataset/Tamil_hasoc_tanglish_test_withlabels(1).tsv',sep='\\t', index_col=[0]) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX7T_uqPJJwi",
        "outputId": "5c087680-7da5-417c-b79f-74a9695510cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7lc6fbOfw16"
      },
      "source": [
        "# **Removing punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "M8iZIjCMfS9r",
        "outputId": "c1cb4b45-4cac-4fef-c5cd-70f3491c2634"
      },
      "source": [
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda x: remove_punctuations(x))\n",
        "train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TA_HL100</th>\n",
              "      <td>Iyaooo Kovam pattutene sothula visatha vachuru...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL101</th>\n",
              "      <td>Asha Apo neenga atha government ku theriya pad...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL102</th>\n",
              "      <td>Bala sundar ayyo sorryantha line ah explain pa...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL105</th>\n",
              "      <td>kalimuthu ne ena lusayaaru edhu panaalum en da...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL109</th>\n",
              "      <td>1st baby ku neat ah feed panunga plzz ipdi iru...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW6620</th>\n",
              "      <td>Yaroda body structure semaya irukum Sema mood ...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW3336</th>\n",
              "      <td>Yenda naangala politics varom nu pala varusham...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_HL1105</th>\n",
              "      <td>Yepdithan seruppala adichalum arasiyalvathikku...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW1915</th>\n",
              "      <td>USER Paithiyam ena unga vanthu full ah forward...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TA_TW4528</th>\n",
              "      <td>RT USER  Itha vidaa kevalam veraa irukaa vijay...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Text Category\n",
              "TA_HL100   Iyaooo Kovam pattutene sothula visatha vachuru...      NOT\n",
              "TA_HL101   Asha Apo neenga atha government ku theriya pad...      NOT\n",
              "TA_HL102   Bala sundar ayyo sorryantha line ah explain pa...      NOT\n",
              "TA_HL105   kalimuthu ne ena lusayaaru edhu panaalum en da...      NOT\n",
              "TA_HL109   1st baby ku neat ah feed panunga plzz ipdi iru...      NOT\n",
              "...                                                      ...      ...\n",
              "TA_TW6620  Yaroda body structure semaya irukum Sema mood ...      OFF\n",
              "TA_TW3336  Yenda naangala politics varom nu pala varusham...      OFF\n",
              "TA_HL1105  Yepdithan seruppala adichalum arasiyalvathikku...      OFF\n",
              "TA_TW1915  USER Paithiyam ena unga vanthu full ah forward...      OFF\n",
              "TA_TW4528  RT USER  Itha vidaa kevalam veraa irukaa vijay...      OFF\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91j5V_0sf3vs"
      },
      "source": [
        "# **Spliting to Dev Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rlp7aL2fSzv"
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(train['Text'], train['Category'], test_size=0.30, random_state=42)\n",
        "\n",
        "X_test= test['Text']\n",
        "y_test= test['Category']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMN4auxRwBca"
      },
      "source": [
        "# **Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRps_FtfSwz"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "y_train = Encoder.fit_transform(y_train)\n",
        "y_test = Encoder.transform(y_test)\n",
        "y_dev = Encoder.transform(y_dev)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfDL9FMiMSj"
      },
      "source": [
        "# **Long Short Term Memory(LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTykTpIfStM"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in X_train]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in X_dev]\n",
        "test_onehot = [one_hot(words, voc_size)for words in X_test]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y-qxoRIfSqA"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=100\n",
        "X_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "X_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "X_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDK7UZmi0Du",
        "outputId": "29c51adb-6692-467f-fa3f-65eaa37bf491"
      },
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "\n",
        "#input layer\n",
        "model.add(LSTM(1000, input_shape=(1000,1), return_sequences=False))\n",
        "\n",
        "#hidded layer\n",
        "model.add(Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6E1oUOkAdj",
        "outputId": "21f59ea6-cebe-4107-caae-d647de973952"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 40)           40000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1000)              4164000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 4,707,005\n",
            "Trainable params: 4,707,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf2IrBnGkAZV",
        "outputId": "b7818244-d338-4224-b0fc-73869b7881e8"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 32s 193ms/step - loss: 6.0777 - accuracy: 0.4803 - val_loss: 2.9268 - val_accuracy: 0.4750\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 7s 170ms/step - loss: 2.5848 - accuracy: 0.5036 - val_loss: 1.9502 - val_accuracy: 0.5250\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 1.7479 - accuracy: 0.5497 - val_loss: 1.3971 - val_accuracy: 0.5742\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 1.2969 - accuracy: 0.5983 - val_loss: 1.1517 - val_accuracy: 0.5883\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 0.9743 - accuracy: 0.7084 - val_loss: 1.0327 - val_accuracy: 0.6042\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 0.7967 - accuracy: 0.7261 - val_loss: 0.9459 - val_accuracy: 0.6200\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 8s 174ms/step - loss: 0.6627 - accuracy: 0.7576 - val_loss: 0.8495 - val_accuracy: 0.6575\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 0.5664 - accuracy: 0.7896 - val_loss: 0.9141 - val_accuracy: 0.5842\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 8s 181ms/step - loss: 0.5121 - accuracy: 0.7976 - val_loss: 0.7660 - val_accuracy: 0.7025\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 8s 172ms/step - loss: 0.4456 - accuracy: 0.8470 - val_loss: 0.8226 - val_accuracy: 0.7050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvA2qvy7kTNK"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg-EuT36KHbG"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "pred_LSTM = model.predict(X_test)\n",
        "#predictions = np.around(predictions)\n",
        "y_test_non_category = y_test\n",
        "y_predict_non_category = [ np.argmax(t) for t in pred_LSTM ]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6iwNPOKKKE5",
        "outputId": "3aa68ccd-1662-443c-9011-5e5f400586b0"
      },
      "source": [
        "#classification report\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test_non_category, y_predict_non_category)) \n",
        "print(classification_report(y_test_non_category, y_predict_non_category, zero_division=0))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[374  91]\n",
            " [181 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.80      0.73       465\n",
            "           1       0.76      0.62      0.68       475\n",
            "\n",
            "    accuracy                           0.71       940\n",
            "   macro avg       0.72      0.71      0.71       940\n",
            "weighted avg       0.72      0.71      0.71       940\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgTg7cF9rmp"
      },
      "source": [
        "# **MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abuz7CFk9peD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b8176b-8cfb-4868-ef4d-e6d970fdfa91"
      },
      "source": [
        "#Simple Neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising\n",
        "MLP = Sequential()\n",
        "\n",
        "# Adding input layer and the first hidden layer\n",
        "MLP.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = sent_length))\n",
        "\n",
        "# Adding second hidden layer\n",
        "MLP.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding output layer\n",
        "MLP.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "MLP.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "MLP.fit(X_train, y_train, batch_size =50 , epochs = 10)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = MLP.predict(X_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56/56 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4939\n",
            "Epoch 2/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5154\n",
            "Epoch 3/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5033\n",
            "Epoch 4/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5034\n",
            "Epoch 5/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4901\n",
            "Epoch 6/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5031\n",
            "Epoch 7/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5082\n",
            "Epoch 8/10\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5055\n",
            "Epoch 9/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5067\n",
            "Epoch 10/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl5JsS_xJaBZ"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "pred_MLP = MLP.predict(X_test)\n",
        "\n",
        "y_test_non_category = y_test\n",
        "y_predict_non_category = [ np.argmax(t) for t in pred_MLP ]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwnAfRWBKdiP",
        "outputId": "9c9a1142-9e0b-43bf-a9ef-5621f77809d2"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test_non_category, y_predict_non_category)) \n",
        "print(classification_report(y_test_non_category, y_predict_non_category, zero_division=0))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0 465]\n",
            " [  0 475]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       465\n",
            "           1       0.51      1.00      0.67       475\n",
            "\n",
            "    accuracy                           0.51       940\n",
            "   macro avg       0.25      0.50      0.34       940\n",
            "weighted avg       0.26      0.51      0.34       940\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv7mWYnaKi8n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}