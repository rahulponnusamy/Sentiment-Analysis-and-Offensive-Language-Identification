{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM and MLP for mal .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdbxAM5VEc8-"
      },
      "source": [
        "**Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTmKTgSeeuQ"
      },
      "source": [
        "#importing required libaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re \n",
        "import string\n",
        "\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkpCVt-IEhxb"
      },
      "source": [
        "**Malayalam Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsvufK8Ylh05"
      },
      "source": [
        "#reading the Malayalam dataset\n",
        "train=pd.read_csv('/content/drive/MyDrive/offensive language/Malayalam dataset/Mal_Training_data.tsv',sep='\\t', index_col=[0])\n",
        "test=pd.read_csv('/content/drive/MyDrive/offensive language/Malayalam dataset/mal_test_data_with_labels.tsv',sep='\\t', index_col=[0])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7lc6fbOfw16"
      },
      "source": [
        "# **Removing punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "M8iZIjCMfS9r",
        "outputId": "d7f2e9b8-dc81-49e8-cf31-f6864b820c5f"
      },
      "source": [
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['Text']=train['Text'].apply(lambda x: remove_punctuations(x))\n",
        "train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MA_YT001</th>\n",
              "      <td>Thaankal enthaan cheyyarullathðŸ˜›</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT002</th>\n",
              "      <td>Ee theetam WCC feminichigalude news aarkk vena...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT003</th>\n",
              "      <td>fukru nem tiktok oolakale vilich charcha nadat...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT004</th>\n",
              "      <td>Aashiq abu produce cheytharunnel ee problems u...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT005</th>\n",
              "      <td>Pennungal oru team aayal ath moonjum ennu epoo...</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3996</th>\n",
              "      <td>Eee parasayam thanne thettanu Ella achanmaraya...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3997</th>\n",
              "      <td>Ente bagathum thetundh ee vazhikke veraan paad...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3998</th>\n",
              "      <td>Kuttiye njan kettikolaam swarnam onnum venda e...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT3999</th>\n",
              "      <td>Chumma veettil irunna chakkiye trollanmaarkku ...</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MA_YT4000</th>\n",
              "      <td>Kalidasan nalla look aayallo kanan Ã°Å¸ËœÂ¬</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Text Category\n",
              "MA_YT001                     Thaankal enthaan cheyyarullathðŸ˜›      NOT\n",
              "MA_YT002   Ee theetam WCC feminichigalude news aarkk vena...      OFF\n",
              "MA_YT003   fukru nem tiktok oolakale vilich charcha nadat...      OFF\n",
              "MA_YT004   Aashiq abu produce cheytharunnel ee problems u...      NOT\n",
              "MA_YT005   Pennungal oru team aayal ath moonjum ennu epoo...      OFF\n",
              "...                                                      ...      ...\n",
              "MA_YT3996  Eee parasayam thanne thettanu Ella achanmaraya...      NOT\n",
              "MA_YT3997  Ente bagathum thetundh ee vazhikke veraan paad...      NOT\n",
              "MA_YT3998  Kuttiye njan kettikolaam swarnam onnum venda e...      NOT\n",
              "MA_YT3999  Chumma veettil irunna chakkiye trollanmaarkku ...      NOT\n",
              "MA_YT4000            Kalidasan nalla look aayallo kanan Ã°Å¸ËœÂ¬      NOT\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91j5V_0sf3vs"
      },
      "source": [
        "# **Spliting to Dev Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rlp7aL2fSzv"
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(train['Text'], train['Category'], test_size=0.30, random_state=42)\n",
        "\n",
        "X_test= test['Text']\n",
        "y_test= test['Category']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMN4auxRwBca"
      },
      "source": [
        "# **Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRps_FtfSwz"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "y_train = Encoder.fit_transform(y_train)\n",
        "y_test = Encoder.transform(y_test)\n",
        "y_dev = Encoder.transform(y_dev)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfDL9FMiMSj"
      },
      "source": [
        "# **Long Short Term Memory(LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTykTpIfStM"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in X_train]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in X_dev]\n",
        "test_onehot = [one_hot(words, voc_size)for words in X_test]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y-qxoRIfSqA"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=100\n",
        "X_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "X_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "X_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqDK7UZmi0Du",
        "outputId": "d0e2c35b-89ff-48ba-ca03-7e55fd65ded2"
      },
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "\n",
        "#input layer\n",
        "model.add(LSTM(1000, input_shape=(1000,1), return_sequences=False))\n",
        "\n",
        "#hidded layer\n",
        "model.add(Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6E1oUOkAdj",
        "outputId": "3daf3da2-ff00-4a9c-c750-8c3115560404"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 40)           40000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1000)              4164000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 4,707,005\n",
            "Trainable params: 4,707,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf2IrBnGkAZV",
        "outputId": "b606eba3-3e5f-400c-d553-2d058750e6bd"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=10, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 32s 186ms/step - loss: 5.9846 - accuracy: 0.4646 - val_loss: 2.7331 - val_accuracy: 0.4925\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 2.4377 - accuracy: 0.5218 - val_loss: 1.9005 - val_accuracy: 0.5075\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 1.7522 - accuracy: 0.5184 - val_loss: 1.4743 - val_accuracy: 0.5033\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 7s 161ms/step - loss: 1.3550 - accuracy: 0.6475 - val_loss: 1.2832 - val_accuracy: 0.5275\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 7s 162ms/step - loss: 1.0749 - accuracy: 0.6927 - val_loss: 1.2100 - val_accuracy: 0.5017\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 7s 163ms/step - loss: 0.9189 - accuracy: 0.6988 - val_loss: 1.1415 - val_accuracy: 0.5117\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.7721 - accuracy: 0.7248 - val_loss: 1.0988 - val_accuracy: 0.5317\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.7137 - accuracy: 0.7075 - val_loss: 1.0775 - val_accuracy: 0.5050\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 7s 163ms/step - loss: 0.6567 - accuracy: 0.7060 - val_loss: 1.0486 - val_accuracy: 0.5050\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 7s 164ms/step - loss: 0.6361 - accuracy: 0.7109 - val_loss: 1.0414 - val_accuracy: 0.5267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvA2qvy7kTNK"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEt16KiWHR2R"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "pred_LSTM = model.predict(X_test)\n",
        "#predictions = np.around(predictions)\n",
        "y_test_non_category = y_test\n",
        "y_predict_non_category = [ np.argmax(t) for t in pred_LSTM ]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZsJoibHVPT",
        "outputId": "5b7e8ce3-760f-45b6-d445-e63706dbd6dc"
      },
      "source": [
        "#classification report\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test_non_category, y_predict_non_category)) \n",
        "print(classification_report(y_test_non_category, y_predict_non_category, zero_division=0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[251 222]\n",
            " [251 227]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.53      0.51       473\n",
            "           1       0.51      0.47      0.49       478\n",
            "\n",
            "    accuracy                           0.50       951\n",
            "   macro avg       0.50      0.50      0.50       951\n",
            "weighted avg       0.50      0.50      0.50       951\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOgTg7cF9rmp"
      },
      "source": [
        "# **MLP**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abuz7CFk9peD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a864f95f-bc76-4c44-bfdf-25dd4aecec23"
      },
      "source": [
        "#Simple Neural network\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising\n",
        "MLP = Sequential()\n",
        "\n",
        "# Adding input layer and the first hidden layer\n",
        "MLP.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = sent_length))\n",
        "\n",
        "# Adding second hidden layer\n",
        "MLP.add(Dense(units = len(train.Category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding output layer\n",
        "MLP.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "MLP.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "MLP.fit(X_train, y_train, batch_size =50 , epochs = 10)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = MLP.predict(X_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "56/56 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5148\n",
            "Epoch 2/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5251\n",
            "Epoch 3/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5164\n",
            "Epoch 4/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4993\n",
            "Epoch 5/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5158\n",
            "Epoch 6/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5199\n",
            "Epoch 7/10\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5370\n",
            "Epoch 8/10\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5425\n",
            "Epoch 9/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5280\n",
            "Epoch 10/10\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGH6ldaCBbmN"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "pred_MLP = MLP.predict(X_test)\n",
        "\n",
        "y_test_non_category = y_test\n",
        "y_predict_non_category = [ np.argmax(t) for t in pred_MLP ]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPzdL5TeBhji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12956d6b-6f28-452c-9ca6-19502ff1f05a"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(confusion_matrix(y_test_non_category, y_predict_non_category)) \n",
        "print(classification_report(y_test_non_category, y_predict_non_category, zero_division=0))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[396  77]\n",
            " [405  73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.84      0.62       473\n",
            "           1       0.49      0.15      0.23       478\n",
            "\n",
            "    accuracy                           0.49       951\n",
            "   macro avg       0.49      0.49      0.43       951\n",
            "weighted avg       0.49      0.49      0.43       951\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}