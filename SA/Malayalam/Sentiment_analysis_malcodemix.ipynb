{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Sentiment analysis-tamilcodemix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWJYw_ypqQ6"
      },
      "source": [
        "## importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ_VyPAfpqRM"
      },
      "source": [
        "#importing necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2UQ4xa2eRgt",
        "outputId": "6ee3dfa8-f333-4053-e0cb-79459a379c2f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgQDvezuXJXh"
      },
      "source": [
        "## Precessing with datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-uQA5QodWD"
      },
      "source": [
        "#importing Malayalam datasets\n",
        "train=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/Mal_sentiment_full_train.tsv',sep='\\t')\n",
        "dev=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/Mal_sentiment_full_dev.tsv',sep='\\t')\n",
        "test=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/Mal_sentiment_full_test_withoutlabels.tsv',sep='\\t')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "dmJePYlXKiyi",
        "outputId": "41a82772-c7b5-4725-9f40-914164d72302"
      },
      "source": [
        "#Fitting Labels\n",
        "train['category'] = train['category'].str.strip()\n",
        "\n",
        "#Visualizing datas\n",
        "Labels =  train['category'].unique()\n",
        "count =   train['category'].value_counts()\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 7))\n",
        "\n",
        "# creating the bar plot\n",
        "plt.bar(Labels, count, color ='red',  width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Labels\")\n",
        "plt.ylabel(\"No. of Labels\")\n",
        "plt.title(\"Dataframe statistics\")\n",
        "plt.show()\n",
        "\n",
        "#Label counts\n",
        "train['category'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive          6421\n",
              "unknown_state     5279\n",
              "Negative          2105\n",
              "not-malayalam     1157\n",
              "Mixed_feelings     926\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlsCeNKAKirE"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_3FcxCpqRk"
      },
      "source": [
        "## Removing punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivjg-TzApqRk"
      },
      "source": [
        "#removing punctuations\n",
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['text']=train['text'].apply(lambda x: remove_punctuations(x))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xit9OnMZK8m0"
      },
      "source": [
        "#Label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "train['category']=Encoder.fit_transform(train['category'])\n",
        "dev['category']= Encoder.fit_transform(dev['category'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-0iJqOmK_SN",
        "outputId": "18170cfe-bb6e-4555-a36b-71f95c460f3c"
      },
      "source": [
        "train['category'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    6421\n",
              "4    5279\n",
              "1    2105\n",
              "3    1157\n",
              "0     926\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlWopm5orPGV"
      },
      "source": [
        "# **Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ftxgFNLg9S"
      },
      "source": [
        "# Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ0L21-xOYib"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in train['text']]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in dev['text']]\n",
        "test_onehot = [one_hot(words, voc_size)for words in test['text']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbZt1c2HOYfV"
      },
      "source": [
        "#from keras.layers import Embedding\n",
        "#from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length = 30\n",
        "embedded_train = pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_dev = pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knb3Gq_EOYcc"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeT2hX_wOXDw"
      },
      "source": [
        "\n",
        "X_train = np.array(embedded_train)\n",
        "y_train = np.array(train['category'])\n",
        "\n",
        "X_dev =  np.array(embedded_dev)\n",
        "y_dev = np.array(dev['category'])\n",
        "\n",
        "X_test =  np.array(embedded_test)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz0cpU2IoCUa"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0JxZbSZg3fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2407b6-09ef-4ee6-e2a8-e03f0b0a65d4"
      },
      "source": [
        "#Building Neural network\n",
        "\n",
        "dim = 50\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Embedding(voc_size,dim,input_length=sent_length, trainable=True))\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = len(train.category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
        "\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = len(train.category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "#classifier.add(Dense(units = len(train.category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "\n",
        "# Compiling the ANN\n",
        "#classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "history = classifier.fit(X_train, y_train, batch_size = 64 , epochs = 100,validation_data=(X_dev, y_dev))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "249/249 [==============================] - 15s 5ms/step - loss: 1.4868 - accuracy: 0.3572 - val_loss: 1.3549 - val_accuracy: 0.3998\n",
            "Epoch 2/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 1.3141 - accuracy: 0.4076 - val_loss: 1.2975 - val_accuracy: 0.3998\n",
            "Epoch 3/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 1.2575 - accuracy: 0.4038 - val_loss: 1.2965 - val_accuracy: 0.3998\n",
            "Epoch 4/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.2291 - accuracy: 0.4121 - val_loss: 1.2905 - val_accuracy: 0.4185\n",
            "Epoch 5/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.1868 - accuracy: 0.4425 - val_loss: 1.2860 - val_accuracy: 0.4479\n",
            "Epoch 6/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 1.1395 - accuracy: 0.4846 - val_loss: 1.2799 - val_accuracy: 0.4734\n",
            "Epoch 7/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 1.0642 - accuracy: 0.5370 - val_loss: 1.2756 - val_accuracy: 0.4955\n",
            "Epoch 8/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.9790 - accuracy: 0.5947 - val_loss: 1.2932 - val_accuracy: 0.5113\n",
            "Epoch 9/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.8983 - accuracy: 0.6411 - val_loss: 1.3400 - val_accuracy: 0.5153\n",
            "Epoch 10/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.8480 - accuracy: 0.6668 - val_loss: 1.4156 - val_accuracy: 0.4989\n",
            "Epoch 11/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.7869 - accuracy: 0.6983 - val_loss: 1.5302 - val_accuracy: 0.5159\n",
            "Epoch 12/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.7317 - accuracy: 0.7193 - val_loss: 1.5956 - val_accuracy: 0.4994\n",
            "Epoch 13/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.6839 - accuracy: 0.7468 - val_loss: 1.7457 - val_accuracy: 0.5057\n",
            "Epoch 14/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.7630 - val_loss: 1.8977 - val_accuracy: 0.5051\n",
            "Epoch 15/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.6051 - accuracy: 0.7752 - val_loss: 2.0469 - val_accuracy: 0.4966\n",
            "Epoch 16/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.7978 - val_loss: 2.2060 - val_accuracy: 0.4915\n",
            "Epoch 17/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.5269 - accuracy: 0.8145 - val_loss: 2.3982 - val_accuracy: 0.4989\n",
            "Epoch 18/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.8252 - val_loss: 2.5667 - val_accuracy: 0.4847\n",
            "Epoch 19/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.8440 - val_loss: 2.7380 - val_accuracy: 0.4841\n",
            "Epoch 20/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8517 - val_loss: 2.9791 - val_accuracy: 0.4853\n",
            "Epoch 21/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8592 - val_loss: 3.1716 - val_accuracy: 0.4773\n",
            "Epoch 22/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8674 - val_loss: 3.3599 - val_accuracy: 0.4790\n",
            "Epoch 23/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.3674 - accuracy: 0.8736 - val_loss: 3.6086 - val_accuracy: 0.4728\n",
            "Epoch 24/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8813 - val_loss: 3.8560 - val_accuracy: 0.4734\n",
            "Epoch 25/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8832 - val_loss: 4.1610 - val_accuracy: 0.4734\n",
            "Epoch 26/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.3191 - accuracy: 0.8887 - val_loss: 4.3760 - val_accuracy: 0.4694\n",
            "Epoch 27/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.3154 - accuracy: 0.8911 - val_loss: 4.5845 - val_accuracy: 0.4660\n",
            "Epoch 28/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8867 - val_loss: 4.8674 - val_accuracy: 0.4649\n",
            "Epoch 29/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.8973 - val_loss: 5.0737 - val_accuracy: 0.4666\n",
            "Epoch 30/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2841 - accuracy: 0.8939 - val_loss: 5.3811 - val_accuracy: 0.4683\n",
            "Epoch 31/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8952 - val_loss: 5.6124 - val_accuracy: 0.4581\n",
            "Epoch 32/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9025 - val_loss: 5.8514 - val_accuracy: 0.4621\n",
            "Epoch 33/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.9052 - val_loss: 5.9483 - val_accuracy: 0.4558\n",
            "Epoch 34/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9076 - val_loss: 6.3659 - val_accuracy: 0.4587\n",
            "Epoch 35/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9133 - val_loss: 6.5832 - val_accuracy: 0.4587\n",
            "Epoch 36/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2505 - accuracy: 0.9161 - val_loss: 6.7739 - val_accuracy: 0.4530\n",
            "Epoch 37/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2365 - accuracy: 0.9250 - val_loss: 6.8740 - val_accuracy: 0.4490\n",
            "Epoch 38/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9292 - val_loss: 7.1337 - val_accuracy: 0.4524\n",
            "Epoch 39/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.2230 - accuracy: 0.9289 - val_loss: 7.3239 - val_accuracy: 0.4530\n",
            "Epoch 40/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2190 - accuracy: 0.9337 - val_loss: 7.5621 - val_accuracy: 0.4490\n",
            "Epoch 41/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2229 - accuracy: 0.9305 - val_loss: 7.8362 - val_accuracy: 0.4524\n",
            "Epoch 42/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9349 - val_loss: 8.0039 - val_accuracy: 0.4564\n",
            "Epoch 43/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.9318 - val_loss: 8.3103 - val_accuracy: 0.4456\n",
            "Epoch 44/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2167 - accuracy: 0.9326 - val_loss: 8.3162 - val_accuracy: 0.4428\n",
            "Epoch 45/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.2090 - accuracy: 0.9403 - val_loss: 8.4363 - val_accuracy: 0.4541\n",
            "Epoch 46/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9442 - val_loss: 8.7156 - val_accuracy: 0.4456\n",
            "Epoch 47/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9424 - val_loss: 9.0563 - val_accuracy: 0.4456\n",
            "Epoch 48/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9478 - val_loss: 9.0900 - val_accuracy: 0.4507\n",
            "Epoch 49/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1932 - accuracy: 0.9443 - val_loss: 9.4129 - val_accuracy: 0.4439\n",
            "Epoch 50/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9495 - val_loss: 9.3949 - val_accuracy: 0.4462\n",
            "Epoch 51/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1860 - accuracy: 0.9490 - val_loss: 9.4964 - val_accuracy: 0.4445\n",
            "Epoch 52/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1929 - accuracy: 0.9456 - val_loss: 9.9612 - val_accuracy: 0.4456\n",
            "Epoch 53/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9444 - val_loss: 9.7716 - val_accuracy: 0.4451\n",
            "Epoch 54/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.9470 - val_loss: 10.1023 - val_accuracy: 0.4473\n",
            "Epoch 55/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9506 - val_loss: 10.1098 - val_accuracy: 0.4462\n",
            "Epoch 56/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9491 - val_loss: 10.3509 - val_accuracy: 0.4456\n",
            "Epoch 57/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9498 - val_loss: 10.3546 - val_accuracy: 0.4485\n",
            "Epoch 58/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9509 - val_loss: 10.6884 - val_accuracy: 0.4496\n",
            "Epoch 59/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9496 - val_loss: 10.5564 - val_accuracy: 0.4445\n",
            "Epoch 60/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.9519 - val_loss: 10.6853 - val_accuracy: 0.4479\n",
            "Epoch 61/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9534 - val_loss: 11.0637 - val_accuracy: 0.4462\n",
            "Epoch 62/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9531 - val_loss: 10.8567 - val_accuracy: 0.4479\n",
            "Epoch 63/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.9515 - val_loss: 11.0496 - val_accuracy: 0.4411\n",
            "Epoch 64/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9503 - val_loss: 11.2948 - val_accuracy: 0.4417\n",
            "Epoch 65/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1816 - accuracy: 0.9481 - val_loss: 11.0265 - val_accuracy: 0.4349\n",
            "Epoch 66/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9514 - val_loss: 11.2733 - val_accuracy: 0.4479\n",
            "Epoch 67/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9490 - val_loss: 11.4672 - val_accuracy: 0.4468\n",
            "Epoch 68/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1634 - accuracy: 0.9529 - val_loss: 11.5019 - val_accuracy: 0.4388\n",
            "Epoch 69/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1581 - accuracy: 0.9540 - val_loss: 11.7947 - val_accuracy: 0.4428\n",
            "Epoch 70/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9540 - val_loss: 11.7804 - val_accuracy: 0.4468\n",
            "Epoch 71/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1564 - accuracy: 0.9551 - val_loss: 11.8979 - val_accuracy: 0.4383\n",
            "Epoch 72/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9568 - val_loss: 11.8229 - val_accuracy: 0.4456\n",
            "Epoch 73/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9561 - val_loss: 12.1289 - val_accuracy: 0.4456\n",
            "Epoch 74/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9547 - val_loss: 11.7853 - val_accuracy: 0.4439\n",
            "Epoch 75/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9555 - val_loss: 12.2357 - val_accuracy: 0.4507\n",
            "Epoch 76/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9546 - val_loss: 12.1216 - val_accuracy: 0.4445\n",
            "Epoch 77/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1841 - accuracy: 0.9504 - val_loss: 12.3598 - val_accuracy: 0.4439\n",
            "Epoch 78/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9469 - val_loss: 12.2564 - val_accuracy: 0.4451\n",
            "Epoch 79/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1830 - accuracy: 0.9482 - val_loss: 12.6043 - val_accuracy: 0.4422\n",
            "Epoch 80/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.9506 - val_loss: 12.4293 - val_accuracy: 0.4428\n",
            "Epoch 81/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1553 - accuracy: 0.9521 - val_loss: 12.7519 - val_accuracy: 0.4451\n",
            "Epoch 82/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9514 - val_loss: 12.5043 - val_accuracy: 0.4439\n",
            "Epoch 83/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1589 - accuracy: 0.9521 - val_loss: 12.8249 - val_accuracy: 0.4417\n",
            "Epoch 84/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9548 - val_loss: 12.7838 - val_accuracy: 0.4417\n",
            "Epoch 85/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1494 - accuracy: 0.9551 - val_loss: 12.8246 - val_accuracy: 0.4434\n",
            "Epoch 86/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9552 - val_loss: 12.9101 - val_accuracy: 0.4439\n",
            "Epoch 87/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9530 - val_loss: 12.9350 - val_accuracy: 0.4434\n",
            "Epoch 88/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9538 - val_loss: 13.1140 - val_accuracy: 0.4434\n",
            "Epoch 89/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9539 - val_loss: 13.2774 - val_accuracy: 0.4451\n",
            "Epoch 90/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9559 - val_loss: 13.2602 - val_accuracy: 0.4417\n",
            "Epoch 91/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9546 - val_loss: 13.2741 - val_accuracy: 0.4428\n",
            "Epoch 92/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9556 - val_loss: 13.5556 - val_accuracy: 0.4405\n",
            "Epoch 93/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9521 - val_loss: 13.4325 - val_accuracy: 0.4536\n",
            "Epoch 94/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9553 - val_loss: 13.6333 - val_accuracy: 0.4451\n",
            "Epoch 95/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9507 - val_loss: 13.8533 - val_accuracy: 0.4462\n",
            "Epoch 96/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9542 - val_loss: 13.9938 - val_accuracy: 0.4434\n",
            "Epoch 97/100\n",
            "249/249 [==============================] - 1s 2ms/step - loss: 0.1463 - accuracy: 0.9542 - val_loss: 13.7657 - val_accuracy: 0.4422\n",
            "Epoch 98/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9553 - val_loss: 13.9880 - val_accuracy: 0.4428\n",
            "Epoch 99/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1464 - accuracy: 0.9541 - val_loss: 13.9172 - val_accuracy: 0.4507\n",
            "Epoch 100/100\n",
            "249/249 [==============================] - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9543 - val_loss: 13.9704 - val_accuracy: 0.4462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DSbYY5VZode"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_NN = classifier.predict(X_dev)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qisn_mogB5JT",
        "outputId": "318c4e46-e1a5-4472-8f6d-7c12ee9fed6a"
      },
      "source": [
        "y_pred_test_NN"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.8040408e-33, 5.9016395e-23, 1.0000000e+00, 0.0000000e+00,\n",
              "        8.4442306e-12],\n",
              "       [8.1931472e-02, 1.8130160e-03, 4.1893002e-02, 7.3106515e-01,\n",
              "        1.4329728e-01],\n",
              "       [0.0000000e+00, 1.9248133e-38, 9.4006038e-01, 0.0000000e+00,\n",
              "        5.9939675e-02],\n",
              "       ...,\n",
              "       [4.2314467e-28, 1.0792607e-27, 1.1221151e-07, 2.8208542e-09,\n",
              "        9.9999988e-01],\n",
              "       [1.2714414e-06, 9.9944800e-01, 5.5071356e-04, 0.0000000e+00,\n",
              "        2.0687172e-17],\n",
              "       [8.0770135e-02, 9.1562974e-01, 3.6001666e-03, 2.5187287e-31,\n",
              "        1.0651554e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hij1bcrUusaC"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qZitZoJvPEz"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpJsLYpuyYH"
      },
      "source": [
        "Word2vec One_hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxlIGFRiuvS7"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in train['text']]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in dev['text']]\n",
        "test_onehot = [one_hot(words, voc_size)for words in test['text']]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6knphhAu4aR"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=20\n",
        "embedded_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-isMsvRJkn-"
      },
      "source": [
        "#spliting datas for training\n",
        "train['category_category'] = pd.Categorical(train['category'])\n",
        "\n",
        "X_train = np.array(embedded_train)\n",
        "y_train = np.array(train['category'])\n",
        "\n",
        "X_dev =  np.array(embedded_dev)\n",
        "y_dev = np.array(dev['category'])\n",
        "\n",
        "X_test =  np.array(embedded_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uHTb5XQu4Uw",
        "outputId": "8f23ea84-c3bf-4424-befb-1d0bf4665803"
      },
      "source": [
        "dim=500\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "#input layer\n",
        "#model.add(LSTM(100)\n",
        "model.add(LSTM(500, input_shape=(500,1), return_sequences=False))\n",
        "#hidded layer\n",
        "model.add(Dense(250, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBZ37Z-DvChh",
        "outputId": "f45a2733-4bb6-418d-a66f-cadff9ad485c"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 20, 500)           500000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 500)               2002000   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 2,628,505\n",
            "Trainable params: 2,628,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyyW9BEYvISE",
        "outputId": "723ebde0-97ba-48aa-8c77-d826ca40c618"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=100,\n",
        "                    epochs=50, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "159/159 [==============================] - 102s 625ms/step - loss: 2.8173 - accuracy: 0.4295 - val_loss: 1.1265 - val_accuracy: 0.5866\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 101s 633ms/step - loss: 1.0480 - accuracy: 0.5987 - val_loss: 1.0761 - val_accuracy: 0.5866\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.9829 - accuracy: 0.6178 - val_loss: 1.0761 - val_accuracy: 0.5974\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.9375 - accuracy: 0.6391 - val_loss: 1.1190 - val_accuracy: 0.5821\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 99s 626ms/step - loss: 0.8848 - accuracy: 0.6660 - val_loss: 1.0897 - val_accuracy: 0.5883\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 99s 625ms/step - loss: 0.8352 - accuracy: 0.6855 - val_loss: 1.1080 - val_accuracy: 0.5866\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 100s 626ms/step - loss: 0.7694 - accuracy: 0.7168 - val_loss: 1.1267 - val_accuracy: 0.5968\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 102s 641ms/step - loss: 0.7148 - accuracy: 0.7432 - val_loss: 1.1940 - val_accuracy: 0.5719\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 99s 625ms/step - loss: 0.6651 - accuracy: 0.7627 - val_loss: 1.2206 - val_accuracy: 0.5787\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.5986 - accuracy: 0.7962 - val_loss: 1.3047 - val_accuracy: 0.5685\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.5163 - accuracy: 0.8313 - val_loss: 1.4693 - val_accuracy: 0.5612\n",
            "Epoch 12/50\n",
            "159/159 [==============================] - 98s 616ms/step - loss: 0.4391 - accuracy: 0.8580 - val_loss: 1.5974 - val_accuracy: 0.5725\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 98s 615ms/step - loss: 0.3606 - accuracy: 0.8892 - val_loss: 1.7494 - val_accuracy: 0.5555\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.2940 - accuracy: 0.9227 - val_loss: 1.9680 - val_accuracy: 0.5425\n",
            "Epoch 15/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.2347 - accuracy: 0.9435 - val_loss: 2.1725 - val_accuracy: 0.5476\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.1907 - accuracy: 0.9565 - val_loss: 2.2752 - val_accuracy: 0.5334\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 98s 617ms/step - loss: 0.1487 - accuracy: 0.9703 - val_loss: 2.3821 - val_accuracy: 0.5453\n",
            "Epoch 18/50\n",
            "159/159 [==============================] - 98s 617ms/step - loss: 0.1081 - accuracy: 0.9822 - val_loss: 2.5191 - val_accuracy: 0.5544\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0994 - accuracy: 0.9844 - val_loss: 2.6208 - val_accuracy: 0.5357\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 99s 625ms/step - loss: 0.1107 - accuracy: 0.9789 - val_loss: 2.5900 - val_accuracy: 0.5476\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.1170 - accuracy: 0.9763 - val_loss: 2.6849 - val_accuracy: 0.5583\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.0891 - accuracy: 0.9847 - val_loss: 2.4950 - val_accuracy: 0.5549\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.0884 - accuracy: 0.9839 - val_loss: 2.7168 - val_accuracy: 0.5629\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.0849 - accuracy: 0.9848 - val_loss: 2.6813 - val_accuracy: 0.5498\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.0886 - accuracy: 0.9832 - val_loss: 2.7562 - val_accuracy: 0.5555\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - 99s 623ms/step - loss: 0.0799 - accuracy: 0.9847 - val_loss: 2.6947 - val_accuracy: 0.5668\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 100s 629ms/step - loss: 0.0712 - accuracy: 0.9873 - val_loss: 2.7162 - val_accuracy: 0.5685\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 99s 622ms/step - loss: 0.0633 - accuracy: 0.9879 - val_loss: 2.8007 - val_accuracy: 0.5447\n",
            "Epoch 29/50\n",
            "159/159 [==============================] - 98s 618ms/step - loss: 0.0653 - accuracy: 0.9864 - val_loss: 2.7655 - val_accuracy: 0.5595\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.0678 - accuracy: 0.9852 - val_loss: 2.8605 - val_accuracy: 0.5770\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 98s 616ms/step - loss: 0.0666 - accuracy: 0.9875 - val_loss: 2.9300 - val_accuracy: 0.5493\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0769 - accuracy: 0.9829 - val_loss: 2.7366 - val_accuracy: 0.5674\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.0744 - accuracy: 0.9852 - val_loss: 3.0871 - val_accuracy: 0.5561\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0840 - accuracy: 0.9825 - val_loss: 3.1209 - val_accuracy: 0.5640\n",
            "Epoch 35/50\n",
            "159/159 [==============================] - 99s 620ms/step - loss: 0.1122 - accuracy: 0.9755 - val_loss: 3.0248 - val_accuracy: 0.5515\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.0855 - accuracy: 0.9816 - val_loss: 2.8843 - val_accuracy: 0.5527\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0643 - accuracy: 0.9859 - val_loss: 2.7808 - val_accuracy: 0.5561\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.0542 - accuracy: 0.9888 - val_loss: 2.7654 - val_accuracy: 0.5583\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 99s 623ms/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 2.6643 - val_accuracy: 0.5532\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 99s 622ms/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 2.7633 - val_accuracy: 0.5538\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.0392 - accuracy: 0.9904 - val_loss: 2.6781 - val_accuracy: 0.5561\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 99s 625ms/step - loss: 0.0468 - accuracy: 0.9881 - val_loss: 2.7729 - val_accuracy: 0.5572\n",
            "Epoch 43/50\n",
            "159/159 [==============================] - 99s 626ms/step - loss: 0.0373 - accuracy: 0.9914 - val_loss: 2.8808 - val_accuracy: 0.5555\n",
            "Epoch 44/50\n",
            "159/159 [==============================] - 99s 622ms/step - loss: 0.0422 - accuracy: 0.9901 - val_loss: 2.7703 - val_accuracy: 0.5623\n",
            "Epoch 45/50\n",
            "159/159 [==============================] - 99s 621ms/step - loss: 0.0378 - accuracy: 0.9908 - val_loss: 2.7095 - val_accuracy: 0.5657\n",
            "Epoch 46/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0387 - accuracy: 0.9899 - val_loss: 2.7581 - val_accuracy: 0.5578\n",
            "Epoch 47/50\n",
            "159/159 [==============================] - 99s 622ms/step - loss: 0.0336 - accuracy: 0.9914 - val_loss: 2.8477 - val_accuracy: 0.5555\n",
            "Epoch 48/50\n",
            "159/159 [==============================] - 98s 619ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 2.8031 - val_accuracy: 0.5527\n",
            "Epoch 49/50\n",
            "159/159 [==============================] - 98s 617ms/step - loss: 0.0455 - accuracy: 0.9885 - val_loss: 3.0414 - val_accuracy: 0.5549\n",
            "Epoch 50/50\n",
            "159/159 [==============================] - 98s 614ms/step - loss: 0.2488 - accuracy: 0.9378 - val_loss: 2.7866 - val_accuracy: 0.5413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCrdLjbeBbF"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}