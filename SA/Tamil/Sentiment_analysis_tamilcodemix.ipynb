{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Sentiment analysis-tamilcodemix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWJYw_ypqQ6"
      },
      "source": [
        "## importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ_VyPAfpqRM"
      },
      "source": [
        "#importing necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#keras\n",
        "from keras import *\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.optimizers import  Adam\n",
        "from keras import regularizers"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2UQ4xa2eRgt",
        "outputId": "d8c396ad-8955-4d3d-d522-8c4be48616da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgQDvezuXJXh"
      },
      "source": [
        "## Precessing with datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkHI6qjzp7gi"
      },
      "source": [
        "#importing datasets\n",
        "train=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/tamil_sentiment_full_train.tsv',sep='\\t')\n",
        "dev=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/tamil_sentiment_full_dev.tsv',sep='\\t')\n",
        "test=pd.read_csv('/content/drive/MyDrive/project/main/Trials/Dataset/tamil_sentiment_full_test_withoutlabels.tsv',sep='\\t')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "dmJePYlXKiyi",
        "outputId": "cd4f85f8-2388-4b31-b10e-f07d511a94dc"
      },
      "source": [
        "#Fitting Labels\n",
        "train['category'] = train['category'].str.strip()\n",
        "\n",
        "#Visualizing datas\n",
        "Labels =  train['category'].unique()\n",
        "count =   train['category'].value_counts()\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 7))\n",
        "\n",
        "# creating the bar plot\n",
        "plt.bar(Labels, count, color ='red',  width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Labels\")\n",
        "plt.ylabel(\"No. of Labels\")\n",
        "plt.title(\"Dataframe statistics\")\n",
        "plt.show()\n",
        "\n",
        "#Label counts\n",
        "train['category'].value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAG6CAYAAABnShDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxkZX3v8c9XNg27MHKRRQgOJrgN0iJGUUwMIi6olyBeDaMS0ahRY9BgkguoWfAa9YoaDCoBrgq4OzEqIqIQIzqN4rCpjAhhRpZRNolIBH/3j/O0Fk13T88w1TWn5/N+vepVp57znHOe01Vd9T3P2VJVSJIkqV/uN+oGSJIkac0Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkuaFJA9LcnGSnyV5zajbM5eSfCHJ4rWYbv8k3x9GmyQNX7xOnKR1LcnVwA7AXcDdwOXA6cDJVfWrWUy/G/AjYJOqumuWy/wQcFtV/fnatXo0knwV+HBVfXCW9Y8HHlpVL1qLZRWwsKqWr+m0ktY/9sRJGpZnVdWWwEOAE4C/BD40xOU9BLhsupFJNhrisiVpzhniJA1VVd1aVUuA5wOLkzwCIMkzknwnyW1Jrm09TBPOb8+3JLk9yeOT7JHkK0l+muQnST6SZJs2r68ATwHe2+rvmeTUJCcl+XyS/wKeMtMyk+yWpJK8pI27Ockrkjw2ybIktyR57+C6JXlpkita3bOTPGSqv0GS+yf5cGv7LUmWJtkhyd8B+w+0+72t/rtbG25LclGS/Vv5QcBfAc9v9b/byr+a5E/a8EOTfC3Jre3vdFYrn/ibfrdN+/wkByRZMdDOXZJ8Ksmq1tb3zjRPSaNliJM0J6rqW8AKutAC8F/AEcA2wDOAP03ynDbuSe15m6raoqq+AQT4B+DBwO8CuwDHt3n/PnAB8OpW/wdt+v8F/B2wJfDvq1nmhMcBC+lC5/8F/hp4KvBw4LAkTwZIcghdoHoesKAt/4xpVn8xsHVr83bAK4A7quqvJ7X71a3+UmAR8EDgo8DHk9y/qr4I/D1wVqv/6CmW9VbgS8C2wM7Ae9rfaOJv+ug27T2CWOup/BxwDbAbsBNw5kzzlDRahjhJc+nHdMGEqvpqVV1SVb+qqmV0AejJ001YVcur6pyqurOqVgHvnKl+89mq+npbxi9mucy3trpfogt9Z1TVjVW1ki5w7d3qvQL4h6q6oh239/fAoml6435JF94eWlV3V9VFVXXbDOv64ar6aVXdVVXvADYDHraadR1c1kOAB7f1+PdZTrcvXUB+Q1X916Rp13aekobIECdpLu0E3ASQ5HFJzmu77m6lC0XbTzdh2/14ZpKVSW4DPjxT/ebaSfOYzTJvGBi+Y4rXW7ThhwDvbrtHb2nrlbaOk/0/4GzgzCQ/TvJ/kmwyw7oe3XbT3trmvfUs1nXCG1s7vpXksiQvneV0uwDXTHMiydrOU9IQGeIkzYkkj6ULOBO9OB8FlgC7VNXWwPvpggLAVKfN/30rf2RVbQW8aKD+dCbPZ6ZlrqlrgZdX1TYDjwdU1X/cqxFVv6yqN1fVXsDvAc+k2617rza249/eCBwGbFtV2wC3MvPfZnBZ11fVy6rqwcDLgX9K8tBZrs+uSTZeh/OUNESGOElDlWSrJM+kO77qw1V1SRu1JXBTVf0iyb50x69NWAX8CvjtgbItgduBW5PsBLxhLZoz0zLX1PuBNyV5OECSrZP80VQVkzwlySPbcWe30e2enLjUyg3cez3vovsbbJzkWGCrgfE3ALslmfL7O8kfJdm5vbyZLvRNt6xB3wKuA05Isnk7GeMJs5inpBExxEkaln9N8jO6Hp6/pjuG7SUD418JvKXVORb42MSIqvo53QkJX2+7K/cD3gw8hq5X6t+AT61Fm6Zd5pqqqk8Db6PbRXobcCnw9Gmq/w/gE3QB7grga3S7WAHeDRzaznA9kW636xeBH9CdZPAL7rlb+OPt+adJvj3Fsh4LfDPJ7XS9jq+tqqvauOOB09rf9LBJ63M38CzgocB/0p2E8vxZzFPSiHixX0mSpB6yJ06SJKmHDHGSJEk9ZIiTJEnqIUOcJElSD93rekDz3fbbb1+77bbbqJshSZK0WhdddNFPqmrBVOM2uBC32267MT4+PupmSJIkrVaSa6Yb5+5USZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6aGghLskuSc5LcnmSy5K8tpU/MMk5Sa5sz9u28iQ5McnyJMuSPGZgXotb/SuTLB4o3yfJJW2aE5NkWOsjSZK0PhlmT9xdwF9U1V7AfsCrkuwFHAOcW1ULgXPba4CnAwvb4yjgJOhCH3Ac8DhgX+C4ieDX6rxsYLqDhrg+s5f08yFJknpjaCGuqq6rqm+34Z8BVwA7AYcAp7VqpwHPacOHAKdX50JgmyQ7Ak8Dzqmqm6rqZuAc4KA2bququrCqCjh9YF6SJEnz2pwcE5dkN2Bv4JvADlV1XRt1PbBDG94JuHZgshWtbKbyFVOUT7X8o5KMJxlftWrVfVoXSZKk9cHQQ1ySLYBPAq+rqtsGx7UetBp2G6rq5Koaq6qxBQsWDHtxkiRJQzfUEJdkE7oA95Gq+lQrvqHtCqU939jKVwK7DEy+cyubqXznKcolSZLmvWGenRrgQ8AVVfXOgVFLgIkzTBcDnx0oP6KdpbofcGvb7Xo2cGCSbdsJDQcCZ7dxtyXZry3riIF5SZIkzWsbD3HeTwD+GLgkycWt7K+AE4CPJTkSuAY4rI37PHAwsBz4OfASgKq6KclbgaWt3luq6qY2/ErgVOABwBfaQ5Ikad5Ld1jahmNsbKzGx8eHu5C+Xq5jA/ssSJK0vktyUVWNTTXOOzZIkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6qGhhbgkpyS5McmlA2VnJbm4Pa5OcnEr3y3JHQPj3j8wzT5JLkmyPMmJSdLKH5jknCRXtudth7UukiRJ65th9sSdChw0WFBVz6+qRVW1CPgk8KmB0T+cGFdVrxgoPwl4GbCwPSbmeQxwblUtBM5tryVJkjYIQwtxVXU+cNNU41pv2mHAGTPNI8mOwFZVdWFVFXA68Jw2+hDgtDZ82kC5JEnSvDeqY+L2B26oqisHynZP8p0kX0uyfyvbCVgxUGdFKwPYoaqua8PXAztMt7AkRyUZTzK+atWqdbQKkiRJozOqEPcC7tkLdx2wa1XtDbwe+GiSrWY7s9ZLVzOMP7mqxqpqbMGCBWvbZkmSpPXGxnO9wCQbA88D9pkoq6o7gTvb8EVJfgjsCawEdh6YfOdWBnBDkh2r6rq22/XGuWi/JEnS+mAUPXFPBb5XVb/eTZpkQZKN2vBv053AcFXbXXpbkv3acXRHAJ9tky0BFrfhxQPlkiRJ894wLzFyBvAN4GFJViQ5so06nHuf0PAkYFm75MgngFdU1cRJEa8EPggsB34IfKGVnwD8YZIr6YLhCcNaF0mSpPVNusPJNhxjY2M1Pj4+3IV0l7Lrnw3ssyBJ0vouyUVVNTbVOO/YIEmS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHhhbikpyS5MYklw6UHZ9kZZKL2+PggXFvSrI8yfeTPG2g/KBWtjzJMQPluyf5Zis/K8mmw1oXSZKk9c0we+JOBQ6aovxdVbWoPT4PkGQv4HDg4W2af0qyUZKNgPcBTwf2Al7Q6gK8rc3rocDNwJFDXBdJkqT1ytBCXFWdD9w0y+qHAGdW1Z1V9SNgObBveyyvqquq6r+BM4FDkgT4feATbfrTgOes0xWQJElaj43imLhXJ1nWdrdu28p2Aq4dqLOilU1Xvh1wS1XdNal8SkmOSjKeZHzVqlXraj0kSZJGZq5D3EnAHsAi4DrgHXOx0Ko6uarGqmpswYIFc7FISZKkodp4LhdWVTdMDCf5APC59nIlsMtA1Z1bGdOU/xTYJsnGrTdusL4kSdK8N6c9cUl2HHj5XGDizNUlwOFJNkuyO7AQ+BawFFjYzkTdlO7khyVVVcB5wKFt+sXAZ+diHSRJktYHQ+uJS3IGcACwfZIVwHHAAUkWAQVcDbwcoKouS/Ix4HLgLuBVVXV3m8+rgbOBjYBTquqytoi/BM5M8rfAd4APDWtdJEmS1jfpOrU2HGNjYzU+Pj7chSTDnf+wbGCfBUmS1ndJLqqqsanGeccGSZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST00tBCX5JQkNya5dKDs7Um+l2RZkk8n2aaV75bkjiQXt8f7B6bZJ8klSZYnOTFJWvkDk5yT5Mr2vO2w1kWSJGl9M8yeuFOBgyaVnQM8oqoeBfwAeNPAuB9W1aL2eMVA+UnAy4CF7TExz2OAc6tqIXBuey1JkrRBGFqIq6rzgZsmlX2pqu5qLy8Edp5pHkl2BLaqqgurqoDTgee00YcAp7Xh0wbKJUmS5r1RHhP3UuALA693T/KdJF9Lsn8r2wlYMVBnRSsD2KGqrmvD1wM7TLegJEclGU8yvmrVqnXUfEmSpNEZSYhL8tfAXcBHWtF1wK5VtTfweuCjSbaa7fxaL13NMP7kqhqrqrEFCxbch5ZLkiStHzae6wUmeTHwTOAPWviiqu4E7mzDFyX5IbAnsJJ77nLduZUB3JBkx6q6ru12vXGOVkGSJGnk5rQnLslBwBuBZ1fVzwfKFyTZqA3/Nt0JDFe13aW3JdmvnZV6BPDZNtkSYHEbXjxQLkmSNO8NrScuyRnAAcD2SVYAx9GdjboZcE67UsiF7UzUJwFvSfJL4FfAK6pq4qSIV9Kd6foAumPoJo6jOwH4WJIjgWuAw4a1LpIkSeubtD2as6uc3A/YoqpuG16ThmtsbKzGx8eHu5AuoPbPGnwWJEnS8CW5qKrGphq32t2pST6aZKskmwOXApcnecO6bqQkSZJmbzbHxO3Vet6eQ7crc3fgj4faKkmSJM1oNiFukySb0IW4JVX1S2a4nIckSZKGbzYh7p+Bq4HNgfOTPATo7TFxkiRJ88Fqz06tqhOBEweKrknylOE1SZIkSaszbYhL8vrVTPvOddwWSZIkzdJMPXFbzlkrJEmStEamDXFV9ea5bIgkSZJmbzbXidszyblJLm2vH5Xkb4bfNEmSJE1nNmenfoDudlm/BKiqZcDhw2yUJEmSZjabEPdbVfWtSWV3DaMxkiRJmp3ZhLifJNmDdoHfJIcC1w21VZIkSZrRaq8TB7wKOBn4nSQrgR8BLxxqqyRJkjSj2Vzs9yrgqUk2B+5XVT8bfrMkSZI0k9mcnbpdkhOBC4CvJnl3ku2G3zRJkiRNZzbHxJ0JrAL+J3BoGz5rmI2SJEnSzGZzTNyOVfXWgdd/m+T5w2qQJEmSVm82PXFfSnJ4kvu1x2HA2cNumCRJkqY3bU9ckp/RXVYkwOuAD7dR9wNuB44eeuskSZI0pZnunbrlXDZEkiRJszebY+JIsi2wELj/RFlVnT+sRkmSJGlmqw1xSf4EeC2wM3AxsB/wDeD3h9s0SZIkTWc2Jza8FngscE1VPQXYG7hlqK2SJEnSjGYT4n5RVb8ASLJZVX0PeNhwmyVJkqSZzOaYuBVJtgE+A5yT5GbgmuE2S5IkSTOZzb1Tn9sGj09yHrA18IWhtkqSJEkzmtXZqROq6msASf4T2HUoLZIkSdJqzeaYuKlknbZCkiRJa2RtQ1yt01ZIkiRpjcx0263XTzcK2GI4zZEkSdJszHRM3Ey33Xr3um6IJEmSZm+me6e+eS4bIkmSpNlb22PiJEmSNEKGOEmSpB6aNsQleW17fsLcNUeSJEmzMVNP3Eva83vmoiGSJEmavZlC3BVJrgQelmTZwOOSJMtmM/MkpyS5McmlA2UPTHJOkivb87atPElOTLK8LecxA9MsbvWvTLJ4oHyf1p7lbVovQixJkjYI04a4qnoBsD+wHHjWwOOZ7Xk2TgUOmlR2DHBuVS0Ezm2vAZ4OLGyPo4CToAt9wHHA44B9geMmgl+r87KB6SYvS5IkaV6a8cSGqrq+qh4NXEd33bgtgR9X1TWzmXlVnQ/cNKn4EOC0Nnwa8JyB8tOrcyGwTZIdgacB51TVTVV1M3AOcFAbt1VVXVhVBZw+MC9JkqR5baaL/QKQ5Ml0Aelqurs17JJkcQtoa2OHqrquDV8P7NCGdwKuHai3opXNVL5iivKp1uEout49dt1117VstiRJ0vpjtSEOeCdwYFV9HyDJnsAZwD73deFVVUmGfh/WqjoZOBlgbGzM+75KkqTem8114jaZCHAAVfUDYJP7sMwb2q5Q2vONrXwlsMtAvZ1b2UzlO09RLkmSNO/NJsSNJ/lgkgPa4wPA+H1Y5hJg4gzTxcBnB8qPaGep7gfc2na7ng0cmGTbdkLDgcDZbdxtSfZrZ6UeMTAvSZKkeW02u1P/FHgV8Jr2+gLgn2Yz8yRnAAcA2ydZQXeW6QnAx5IcCVwDHNaqfx44mO5s2J/TrlNXVTcleSuwtNV7S1VNnCzxSrozYB8AfKE9JEmS5r10J3ZuOMbGxmp8/L50JM5CXy9Xt4F9FiRJWt8luaiqxqYa571TJUmSesgQJ0mS1EOGOEmSpB5aqxDXLp4rSZKkEVnbnrieHrkvSZI0P6xViKuqf17XDZEkSdLsrTbEJdk5yaeTrEpyY5JPJtl5ddNJkiRpeGbTE/cvdHdT2BF4MPCvrUySJEkjMpsQt6Cq/qWq7mqPU4EFQ26XJEmSZjCbEPfTJC9KslF7vAj46bAbJkmSpOnNJsS9lO7+ptcD1wGH0u5rKkmSpNHYeHUVquoa4Nlz0BZJkiTN0rQhLsmxM0xXVfXWIbRHkiRJszBTT9x/TVG2OXAksB1giJMkSRqRaUNcVb1jYjjJlsBr6Y6FOxN4x3TTSZIkafhmPCYuyQOB1wMvBE4DHlNVN89FwyRJkjS9mY6JezvwPOBk4JFVdfuctUqSJEkzmukSI39Bd4eGvwF+nOS29vhZktvmpnmSJEmaykzHxM3mGnKSJEkaAYOaJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSD815iEvysCQXDzxuS/K6JMcnWTlQfvDANG9KsjzJ95M8baD8oFa2PMkxc70ukiRJo7LxXC+wqr4PLAJIshGwEvg08BLgXVX1j4P1k+wFHA48HHgw8OUke7bR7wP+EFgBLE2ypKoun5MVkSRJGqE5D3GT/AHww6q6Jsl0dQ4BzqyqO4EfJVkO7NvGLa+qqwCSnNnqGuIkSdK8N+pj4g4Hzhh4/eoky5KckmTbVrYTcO1AnRWtbLrye0lyVJLxJOOrVq1ad62XJEkakZGFuCSbAs8GPt6KTgL2oNvVeh3wjnW1rKo6uarGqmpswYIF62q2kiRJIzPK3alPB75dVTcATDwDJPkA8Ln2ciWwy8B0O7cyZiiXJEma10a5O/UFDOxKTbLjwLjnApe24SXA4Uk2S7I7sBD4FrAUWJhk99ard3irK0mSNO+NpCcuyeZ0Z5W+fKD4/yRZBBRw9cS4qrosycfoTli4C3hVVd3d5vNq4GxgI+CUqrpszlZCkiRphFJVo27DnBobG6vx8fHhLmT6M23XbxvYZ0GSpPVdkouqamyqcaM+O1WSJElrwRAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYcMcZIkST1kiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9dDGo26AtF5LRt2CtVc16hZIkobInjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknpoZCEuydVJLklycZLxVvbAJOckubI9b9vKk+TEJMuTLEvymIH5LG71r0yyeFTrI0mSNJdG3RP3lKpaVFVj7fUxwLlVtRA4t70GeDqwsD2OAk6CLvQBxwGPA/YFjpsIfpIkSfPZqEPcZIcAp7Xh04DnDJSfXp0LgW2S7Ag8DTinqm6qqpuBc4CD5rrRkiRJc22UIa6ALyW5KMlRrWyHqrquDV8P7NCGdwKuHZh2RSubrlySJGleG+W9U59YVSuTPAg4J8n3BkdWVSVZJzd/bCHxKIBdd911XcxSkiRppEbWE1dVK9vzjcCn6Y5pu6HtJqU939iqrwR2GZh851Y2XfnkZZ1cVWNVNbZgwYJ1vSqSJElzbiQhLsnmSbacGAYOBC4FlgATZ5guBj7bhpcAR7SzVPcDbm27Xc8GDkyybTuh4cBWJkmSNK+NanfqDsCnk0y04aNV9cUkS4GPJTkSuAY4rNX/PHAwsBz4OfASgKq6KclbgaWt3luq6qa5Ww1JkqTRSNU6OeysN8bGxmp8fHy4C+nCaf9sYJ+FWenrewm+n5I0DyS5aOBSbPewvl1iRJIkSbNgiJMkSeohQ5wkSVIPGeIkSZJ6yBAnSZLUQ4Y4SZKkHjLESZIk9ZAhTpIkqYdGdccGSZp7fb14sxduljQFe+IkSZJ6yBAnSZLUQ4Y4SZKkHvKYOElS/3h8o2RPnCRJUh8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6qE5D3FJdklyXpLLk1yW5LWt/PgkK5Nc3B4HD0zzpiTLk3w/ydMGyg9qZcuTHDPX6yJJkjQqG49gmXcBf1FV306yJXBRknPauHdV1T8OVk6yF3A48HDgwcCXk+zZRr8P+ENgBbA0yZKqunxO1kKSJGmE5jzEVdV1wHVt+GdJrgB2mmGSQ4Azq+pO4EdJlgP7tnHLq+oqgCRntrqGOEmSNO+N9Ji4JLsBewPfbEWvTrIsySlJtm1lOwHXDky2opVNVz7Vco5KMp5kfNWqVetwDSRJkkZjZCEuyRbAJ4HXVdVtwEnAHsAiup66d6yrZVXVyVU1VlVjCxYsWFezlSRJGplRHBNHkk3oAtxHqupTAFV1w8D4DwCfay9XArsMTL5zK2OGckmSpHltFGenBvgQcEVVvXOgfMeBas8FLm3DS4DDk2yWZHdgIfAtYCmwMMnuSTalO/lhyVysgyRJ0qiNoifuCcAfA5ckubiV/RXwgiSLgAKuBl4OUFWXJfkY3QkLdwGvqqq7AZK8Gjgb2Ag4paoum8sVkSRJGpVU1ajbMKfGxsZqfHx8uAtJhjv/YdnAPguz0tf3Enw/p9LX99P38t58L7WBSHJRVY1NNc47NkiSJPWQIU6SJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB4yxEmSJPXQKG67JUmS1PHuG2vNnjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1kCFOkiSphwxxkiRJPWSIkyRJ6iFDnCRJUg8Z4iRJknrIECdJktRDhjhJkqQeMsRJkiT1UO9DXJKDknw/yfIkx4y6PZIkSXOh1yEuyUbA+4CnA3sBL0iy12hbJUmSNHy9DnHAvsDyqrqqqv4bOBM4ZMRtkiRJGrqNR92A+2gn4NqB1yuAx02ulOQo4Kj28vYk35+Dtg3L9sBPhjLnZCiz1Yx8P+cP38v5w/dy/pgP7+VDphvR9xA3K1V1MnDyqNuxLiQZr6qxUbdD64bv5/zhezl/+F7OH/P9vez77tSVwC4Dr3duZZIkSfNa30PcUmBhkt2TbAocDiwZcZskSZKGrte7U6vqriSvBs4GNgJOqarLRtysYZsXu4X1a76f84fv5fzhezl/zOv3MlU16jZIkiRpDfV9d6okSaJ3VFgAAAxMSURBVNIGyRAnSZLUQ4Y4aQ0luTvJxUkuTfLxJL+1htM/OMkn2vCiJAcPjHu2t48briSV5B0Dr49OcvwQlvNXk17/x7pehrQhS/LiJA+eVLZd+36+OMn1SVYOvN70Pizr80m2acO339e2ryuGuHWofaDeO+p2zEaSA5L83rqqt4G5o6oWVdUjgP8GXrEmE1fVj6vq0PZyEXDwwLglVXXCumuqpnAn8Lwk2w95OfcIcVXl/9E0WrD+8MDrjZOsSvK59nqdbNy077PPzTB+syRfbj/4z1+L+R+f5Og2/JYkT70v7dVqvRi4R4irqp+27+dFwPuBd028bnd2WitVdXBV3XLfmrvuGeI2XAcAs/lRmW29DdUFwEOTPDDJZ5IsS3JhkkcBJHnywFbgd5JsmWS31ou3KfAW4PkTPxoTGwJJtk5yTZL7tflsnuTaJJsk2SPJF5NclOSCJL8zwvXvo7vozlj788kjkixI8skkS9vjCQPl5yS5LMkH23uzfRv3mfZeXNbuDkOSE4AHtPf1I63s9vZ8ZpJnDCzz1CSHJtkoydvbcpclefnQ/xLrj/8CHpHkAe31HzJwzc853LjZuy1vUVWddV9mVFXHVtWX102zNgztu/GKJB9o/09fSvKAtsfiwvZ/8ekk2yY5FBgDPtL+zx6wmnm/rP1vfbf9j/9WKz81yUlt/le1oH9Ka8epA9NfPQcbfmvMEDeDiR/bgddHty2tryZ5W5JvJflBkv2nmPYZSb6RZPv2ITkxyX+0D8mhrU7al/alSS6Z2PJL8r4kz27Dn05ySht+aZK/m+6DPsN6vCbJ5e0f4Mwku9H1Hv15+/Dvn+RZSb7ZgsaXk+wwTb0pf+Q2REk2Bp4OXAK8GfhOVT2Krgfm9FbtaOBVbatwf+COienbVuGxwFmTfzSq6lbgYuDJreiZwNlV9Uu6APJnVbVPm/8/DW8t5633AS9MsvWk8nfTbbk/FvifwAdb+XHAV6rq4cAngF0Hpnlpey/GgNck2a6qjuE3PbYvnLSMs4DDANIF+T8A/g04Eri1LfuxwMuS7L6O1rcPPg9MhNsXAGdMjMjAXo4kn01yRBt++UBIPrB953473WEOW7Tyg5J8L8m3gedNt/AkDwI+DDy2fd/tkWSfJF9rIf3sJDu2uqvdkJoI52346iRvbm27ZKJ+ptk4SLfR9m8tcFyategV7LGFwPva/9otdP+HpwN/2b5fLwGOq6pPAOPAC9v/2R3TzrHzqap6bFU9GriC7v9twrbA4+k27JYA7wIeDjwyyaJ1uG7rnCFu7W1cVfsCr6P7gv+1JM8FjgEOrqqJe7btCDyR7sd4YovyeXS70x4NPBV4e/uSuIDuBx+6+8Pu1Yb3B85vw1N90KdzDLB3+wd4RVVdzT27mS8A/h3Yr6r2Bs4E3jhNvel+5DYkD0hyMd0XyH8CH6J7b/8fQFV9BdguyVbA14F3JnkNsE1V3bUGyzkLmPjyPhw4q/0w/R7w8daGf6b7bGkNVNVtdD8Mr5k06qnAe9vfdgmwVfubP5Hu/4Kq+iJw88A0r0nyXeBCujvILFzN4r8APCXJZnQbAee3H6ADgSPasr8JbDeLec0nZwKHJ7k/8Ci6v8FUjgKObRvPfwH8Wesh+RvgqVX1GLr/zde3eX0AeBawD/A/plt4Vd0I/AlwQdvo+k/gPcChLaSfAvxdq742G1I/aW07qU0D028cHAT8uKoe3Q7b+OIs5j9f/KiqLm7DFwF70H13fq2VnQY8aS3m+4gWuC8BXkgX0ib8a3XXW7sEuKGqLqmqXwGXAbutzUrMlV5f7HfEPtWeL+Keb/Lv022RH9h+KCZ8pn0oLk+yQyt7InBGVd0N3JDka3Rb4BcAr0uyF3A5sG0Ld4+n+9HZjnt/0AfbMNkyui7nzwCfmabOznQhYUdgU+BH09R7KrBXfnPj362SbFFV682BnnPgjvYl/2uZ5kbIVXVCkn+jO+7t60meBvxilstZAvx9kgfS/QB9BdgcuGXy8rVW/i/wbeBfBsruR7cxc4/3aLr3N8kBdP8Tj6+qnyf5KnD/mRZaVb9o9Z5GF9LPnJgdXTA4e01XZD6oqmWt9/8FdL1y09W7IcmxwHnAc6vqpiTPpNvY/Xp7rzYFvgH8Dt135ZUA6Y67O2qWTXoY8AjgnDbPjYDrJm1ITdTdbBbzG/zNmOgRfCLw3LZeX0wysXFwCfCOJG8DPtc2oDcUdw4M3w1sM5uJkjyObqMW4Niqmnz3plOB51TVd5O8mO5QocnL/NWk5f+K9Twn2RM3s7u4599o8Mt54o2+m3u+yT8EtgT2nDSvwQ/G1L8ITVWtpPvgHkTX83YB3e6X26vqZ1PMb3IbJnsG3e6jxwBL227Ayd4DvLeqHgm8nOl/iCZ+5CYOFN1pAwtw07mAbutu4of9J1V1W5I92lbd2+huEzd5t8vP6D4v99L+rkvpej8/V1V3tw2DHyX5o7asJHn0UNZonquqm4CPcc/dKl8C/mzixcCulK/zm12gB9LtfgHYGri5BbjfAfYbmNcvk2wyzeLPAl5C17s+0ctyNvCnE9Mk2TPJ5mu5en21BPhHBnalTuORwE/5zUHtAc4Z+F7aq6qOnH7yWQlw2cA8H1lVB9J9B94yUL6oqn53FvOb7jfjXqrqB3Tf15cAf9tC64bqVuDm/OawpT8GJnrlfv39WVXfHHg/prr95pZ0IXwT2nf1fGCIm9kNwIPSnbK8Gd2u0NW5hrYPP8nDV1P3ArqD2jdKsoCui/hbbdyFdLtqJ0Lc0e15jaQ7MH6XqjoP+Eu6H50tuHd42JrfHEi8eKB8cr3pfuQ2dMcD+yRZRre7fOJv+Lp2TMsy4Jd0u9IGnUfXsznd2XBnAS9qzxNeCBzZduFdBhyy7lZjg/MOYPBg5dcAY+mOH72c35x5/GbgwHTHyP4RcD3d/8YXgY2TXEH3vl84MK+TgWUTx2xN8iW64x2/PHDG3Afpet6/3Zbzz6znvQBDcArw5qq6ZLoKSfal2w29N3B0uuMGLwSekOShrc7mSfYEvgfslmSPNvkL1qAt3wcWJHl8m+cmSR6+jjekptw4SHfZjJ9X1YeBt9MFug3ZYrrDjZbRHYL0llZ+KvD+zOLEBuB/0+2i/zrd52J+qCofMzzovtR/SBemTqX7sf4qMNbGbw9c3YZfTNebBd0XzOV0+/NPpTuuYmKet7fn0P2DXkq3xfX8gTpH0h0TAbAJ3dlbz2uvdwMuHah7NHD8NO3fhO54t0vaco5p5XvS7Wa9mK434BDgKrqu/rcDX52m3vZ0gWJZW7/3j/o98uFj2A+63WUbt+HHAxePuk3z6THxnTip7AC6Huhff7e29+G7wGNa+bPpNoRCdyjL0vbdtAx4dqtzEN2P9rf5Ta/2dO04YHA8XWA4vy3zMuBlrXx3ugD/3fY9eGwrPx44ug3/+nsfuBrYvg2PDXy/Pgg4t303fwC4rq3j0wa+d5fSfm98+Jj88N6pkrQaSRbS7Xq9H921AV9ZVUtH2yr1XdvDc3dV3dV6/E4qj3fVGjDESZI0Am4c6L4yxM0jSd4HTL5u27ur6l+mqi9JG6IkLwFeO6n461X1qlG0R1pbhjhJkqQe8uxUSZKkHjLESZIk9ZAhTpKatJvUz7Lu8UmOXn3NtZu/JK2OIU6SJKmHDHGSNIMkz0ryzSTfSfLlgXsfAzw6yTeSXJnkZQPTvCHJ0nbnhzdPMc8dk5zfrjR/6cAthSRp1gxxkjSzf6e7X/DedDerf+PAuEfR3Sng8cCxSR7cbp+0ENiX7or/+yR50qR5/i/g7HZh10fTXZlfktbIhnZfPklaUzsDZyXZEdgU+NHAuM9W1R3AHUnOowtuTwQOBL7T6mxBF+rOH5huKXBKuxn3Z6rKECdpjdkTJ0kzew/dPZEfCbwcuP/AuMkX2iy6+3j+Q1Utao+HVtWH7lGp6nzgScBK4NQkRwyv+ZLmK0OcJM1sa7qwBbB40rhDktw/yXZ0N09fCpwNvDTJFgBJdkryoMGJkjwEuKGqPgB8EHjMENsvaZ5yd6ok/cZvJVkx8PqdwPHAx5PcDHwF2H1g/DLgPGB74K1V9WPgx0l+F/hGEoDbgRcBNw5MdwDwhiS/bOPtiZO0xrztliRJUg+5O1WSJKmHDHGSJEk9ZIiTJEnqIUOcJElSDxniJEmSesgQJ0mS1EOGOEmSpB76/48yfi+GNHKyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive          20070\n",
              "unknown_state      5628\n",
              "Negative           4271\n",
              "Mixed_feelings     4020\n",
              "not-Tamil          1667\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlsCeNKAKirE"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0_3FcxCpqRk"
      },
      "source": [
        "## Removing punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivjg-TzApqRk"
      },
      "source": [
        "#removing punctuations\n",
        "import string\n",
        "def remove_punctuations(txt):\n",
        "    text_nopunc=\"\".join([c for c in txt if c not in string.punctuation])\n",
        "    return text_nopunc\n",
        "\n",
        "train['text']=train['text'].apply(lambda x: remove_punctuations(x))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xit9OnMZK8m0"
      },
      "source": [
        "#Label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "train['category']=Encoder.fit_transform(train['category'])\n",
        "dev['category']= Encoder.fit_transform(dev['category'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-0iJqOmK_SN",
        "outputId": "63d7f246-c0c9-49a0-c605-1af64b74532d"
      },
      "source": [
        "train['category'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    20070\n",
              "4     5628\n",
              "1     4271\n",
              "0     4020\n",
              "3     1667\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlWopm5orPGV"
      },
      "source": [
        "# **Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ftxgFNLg9S"
      },
      "source": [
        "# Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ0L21-xOYib"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in train['text']]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in dev['text']]\n",
        "test_onehot = [one_hot(words, voc_size)for words in test['text']]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbZt1c2HOYfV"
      },
      "source": [
        "#from keras.layers import Embedding\n",
        "#from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=20\n",
        "embedded_train = pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_dev = pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knb3Gq_EOYcc"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeT2hX_wOXDw"
      },
      "source": [
        "\n",
        "X_train = np.array(embedded_train)\n",
        "y_train = np.array(train['category'])\n",
        "\n",
        "X_dev =  np.array(embedded_dev)\n",
        "y_dev = np.array(dev['category'])\n",
        "\n",
        "X_test =  np.array(embedded_test)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0JxZbSZg3fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01468907-c6b3-436e-ed9a-7d0edfeb8994"
      },
      "source": [
        "#Building Neural network\n",
        "\n",
        "dim = 40\n",
        "classifier = Sequential()\n",
        "\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length, trainable=True))\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = len(train.category.value_counts()), kernel_initializer = 'uniform', activation = 'relu', input_dim = 20))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = len(train.category.value_counts()), kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "#classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "history = classifier.fit(X_train, y_train, batch_size =100 , epochs = 150,validation_data=(X_dev, y_dev))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 1.4153 - accuracy: 0.5306 - val_loss: 1.2719 - val_accuracy: 0.5697\n",
            "Epoch 2/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2782 - accuracy: 0.5627 - val_loss: 1.2659 - val_accuracy: 0.5697\n",
            "Epoch 3/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2678 - accuracy: 0.5656 - val_loss: 1.2621 - val_accuracy: 0.5697\n",
            "Epoch 4/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2640 - accuracy: 0.5644 - val_loss: 1.2551 - val_accuracy: 0.5697\n",
            "Epoch 5/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2591 - accuracy: 0.5639 - val_loss: 1.2499 - val_accuracy: 0.5697\n",
            "Epoch 6/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2650 - accuracy: 0.5569 - val_loss: 1.2479 - val_accuracy: 0.5697\n",
            "Epoch 7/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2487 - accuracy: 0.5633 - val_loss: 1.2454 - val_accuracy: 0.5697\n",
            "Epoch 8/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2474 - accuracy: 0.5649 - val_loss: 1.2434 - val_accuracy: 0.5697\n",
            "Epoch 9/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2459 - accuracy: 0.5647 - val_loss: 1.2411 - val_accuracy: 0.5697\n",
            "Epoch 10/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2456 - accuracy: 0.5645 - val_loss: 1.2423 - val_accuracy: 0.5697\n",
            "Epoch 11/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2493 - accuracy: 0.5637 - val_loss: 1.2409 - val_accuracy: 0.5697\n",
            "Epoch 12/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2472 - accuracy: 0.5622 - val_loss: 1.2408 - val_accuracy: 0.5697\n",
            "Epoch 13/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2525 - accuracy: 0.5617 - val_loss: 1.2402 - val_accuracy: 0.5697\n",
            "Epoch 14/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5632 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 15/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2503 - accuracy: 0.5622 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 16/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2445 - accuracy: 0.5642 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 17/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2485 - accuracy: 0.5615 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 18/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2503 - accuracy: 0.5612 - val_loss: 1.2393 - val_accuracy: 0.5697\n",
            "Epoch 19/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2409 - accuracy: 0.5668 - val_loss: 1.2398 - val_accuracy: 0.5697\n",
            "Epoch 20/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2390 - accuracy: 0.5684 - val_loss: 1.2406 - val_accuracy: 0.5697\n",
            "Epoch 21/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2476 - accuracy: 0.5612 - val_loss: 1.2403 - val_accuracy: 0.5697\n",
            "Epoch 22/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2458 - accuracy: 0.5635 - val_loss: 1.2393 - val_accuracy: 0.5697\n",
            "Epoch 23/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2498 - accuracy: 0.5613 - val_loss: 1.2413 - val_accuracy: 0.5697\n",
            "Epoch 24/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2396 - accuracy: 0.5672 - val_loss: 1.2406 - val_accuracy: 0.5697\n",
            "Epoch 25/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2421 - accuracy: 0.5658 - val_loss: 1.2410 - val_accuracy: 0.5697\n",
            "Epoch 26/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2501 - accuracy: 0.5585 - val_loss: 1.2424 - val_accuracy: 0.5697\n",
            "Epoch 27/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2439 - accuracy: 0.5647 - val_loss: 1.2400 - val_accuracy: 0.5697\n",
            "Epoch 28/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2579 - accuracy: 0.5552 - val_loss: 1.2411 - val_accuracy: 0.5697\n",
            "Epoch 29/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2480 - accuracy: 0.5631 - val_loss: 1.2410 - val_accuracy: 0.5697\n",
            "Epoch 30/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2394 - accuracy: 0.5678 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 31/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2437 - accuracy: 0.5635 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 32/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2429 - accuracy: 0.5643 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 33/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2457 - accuracy: 0.5627 - val_loss: 1.2419 - val_accuracy: 0.5697\n",
            "Epoch 34/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2405 - accuracy: 0.5660 - val_loss: 1.2417 - val_accuracy: 0.5697\n",
            "Epoch 35/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2461 - accuracy: 0.5621 - val_loss: 1.2406 - val_accuracy: 0.5697\n",
            "Epoch 36/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2460 - accuracy: 0.5623 - val_loss: 1.2410 - val_accuracy: 0.5697\n",
            "Epoch 37/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2498 - accuracy: 0.5607 - val_loss: 1.2405 - val_accuracy: 0.5697\n",
            "Epoch 38/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2435 - accuracy: 0.5649 - val_loss: 1.2400 - val_accuracy: 0.5697\n",
            "Epoch 39/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2472 - accuracy: 0.5633 - val_loss: 1.2408 - val_accuracy: 0.5697\n",
            "Epoch 40/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2414 - accuracy: 0.5654 - val_loss: 1.2398 - val_accuracy: 0.5697\n",
            "Epoch 41/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2446 - accuracy: 0.5635 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 42/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2507 - accuracy: 0.5594 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 43/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2466 - accuracy: 0.5632 - val_loss: 1.2402 - val_accuracy: 0.5697\n",
            "Epoch 44/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2418 - accuracy: 0.5668 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 45/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2500 - accuracy: 0.5612 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 46/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2531 - accuracy: 0.5593 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 47/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2540 - accuracy: 0.5584 - val_loss: 1.2408 - val_accuracy: 0.5697\n",
            "Epoch 48/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2541 - accuracy: 0.5579 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 49/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2476 - accuracy: 0.5625 - val_loss: 1.2422 - val_accuracy: 0.5697\n",
            "Epoch 50/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2470 - accuracy: 0.5624 - val_loss: 1.2397 - val_accuracy: 0.5697\n",
            "Epoch 51/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2490 - accuracy: 0.5628 - val_loss: 1.2412 - val_accuracy: 0.5697\n",
            "Epoch 52/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2493 - accuracy: 0.5615 - val_loss: 1.2402 - val_accuracy: 0.5697\n",
            "Epoch 53/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2425 - accuracy: 0.5662 - val_loss: 1.2411 - val_accuracy: 0.5697\n",
            "Epoch 54/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5616 - val_loss: 1.2403 - val_accuracy: 0.5697\n",
            "Epoch 55/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2459 - accuracy: 0.5629 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 56/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2446 - accuracy: 0.5637 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 57/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2469 - accuracy: 0.5623 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 58/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2479 - accuracy: 0.5615 - val_loss: 1.2400 - val_accuracy: 0.5697\n",
            "Epoch 59/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2523 - accuracy: 0.5594 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 60/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.5628 - val_loss: 1.2393 - val_accuracy: 0.5697\n",
            "Epoch 61/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2509 - accuracy: 0.5583 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 62/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2456 - accuracy: 0.5623 - val_loss: 1.2405 - val_accuracy: 0.5697\n",
            "Epoch 63/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2407 - accuracy: 0.5661 - val_loss: 1.2398 - val_accuracy: 0.5697\n",
            "Epoch 64/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2454 - accuracy: 0.5610 - val_loss: 1.2398 - val_accuracy: 0.5697\n",
            "Epoch 65/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2505 - accuracy: 0.5609 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 66/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2435 - accuracy: 0.5638 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 67/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2459 - accuracy: 0.5613 - val_loss: 1.2390 - val_accuracy: 0.5697\n",
            "Epoch 68/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2502 - accuracy: 0.5616 - val_loss: 1.2390 - val_accuracy: 0.5697\n",
            "Epoch 69/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2464 - accuracy: 0.5628 - val_loss: 1.2404 - val_accuracy: 0.5697\n",
            "Epoch 70/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2398 - accuracy: 0.5667 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 71/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2431 - accuracy: 0.5643 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 72/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.5647 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 73/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.5635 - val_loss: 1.2390 - val_accuracy: 0.5697\n",
            "Epoch 74/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2411 - accuracy: 0.5650 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 75/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2437 - accuracy: 0.5639 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 76/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2404 - accuracy: 0.5666 - val_loss: 1.2399 - val_accuracy: 0.5697\n",
            "Epoch 77/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2462 - accuracy: 0.5616 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 78/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2500 - accuracy: 0.5610 - val_loss: 1.2388 - val_accuracy: 0.5697\n",
            "Epoch 79/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2552 - accuracy: 0.5582 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 80/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2444 - accuracy: 0.5654 - val_loss: 1.2397 - val_accuracy: 0.5697\n",
            "Epoch 81/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2479 - accuracy: 0.5614 - val_loss: 1.2385 - val_accuracy: 0.5697\n",
            "Epoch 82/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2347 - accuracy: 0.5693 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 83/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2438 - accuracy: 0.5626 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 84/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.5630 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 85/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2488 - accuracy: 0.5610 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 86/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2359 - accuracy: 0.5673 - val_loss: 1.2401 - val_accuracy: 0.5697\n",
            "Epoch 87/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2468 - accuracy: 0.5627 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 88/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2435 - accuracy: 0.5636 - val_loss: 1.2400 - val_accuracy: 0.5697\n",
            "Epoch 89/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2517 - accuracy: 0.5575 - val_loss: 1.2397 - val_accuracy: 0.5697\n",
            "Epoch 90/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2441 - accuracy: 0.5632 - val_loss: 1.2390 - val_accuracy: 0.5697\n",
            "Epoch 91/150\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 1.2529 - accuracy: 0.5569 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 92/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2435 - accuracy: 0.5632 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 93/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2390 - accuracy: 0.5654 - val_loss: 1.2398 - val_accuracy: 0.5697\n",
            "Epoch 94/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2491 - accuracy: 0.5616 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 95/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2391 - accuracy: 0.5662 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 96/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2399 - accuracy: 0.5668 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 97/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2499 - accuracy: 0.5606 - val_loss: 1.2382 - val_accuracy: 0.5697\n",
            "Epoch 98/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2395 - accuracy: 0.5654 - val_loss: 1.2382 - val_accuracy: 0.5697\n",
            "Epoch 99/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2421 - accuracy: 0.5663 - val_loss: 1.2380 - val_accuracy: 0.5697\n",
            "Epoch 100/150\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 1.2388 - accuracy: 0.5677 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 101/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2473 - accuracy: 0.5625 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 102/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2436 - accuracy: 0.5638 - val_loss: 1.2387 - val_accuracy: 0.5697\n",
            "Epoch 103/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2451 - accuracy: 0.5640 - val_loss: 1.2393 - val_accuracy: 0.5697\n",
            "Epoch 104/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2481 - accuracy: 0.5611 - val_loss: 1.2405 - val_accuracy: 0.5697\n",
            "Epoch 105/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5606 - val_loss: 1.2385 - val_accuracy: 0.5697\n",
            "Epoch 106/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2373 - accuracy: 0.5682 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 107/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2449 - accuracy: 0.5635 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 108/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2458 - accuracy: 0.5628 - val_loss: 1.2385 - val_accuracy: 0.5697\n",
            "Epoch 109/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2398 - accuracy: 0.5661 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 110/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2434 - accuracy: 0.5634 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 111/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2496 - accuracy: 0.5604 - val_loss: 1.2381 - val_accuracy: 0.5697\n",
            "Epoch 112/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2340 - accuracy: 0.5683 - val_loss: 1.2381 - val_accuracy: 0.5697\n",
            "Epoch 113/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2477 - accuracy: 0.5616 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 114/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2391 - accuracy: 0.5663 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 115/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2473 - accuracy: 0.5620 - val_loss: 1.2384 - val_accuracy: 0.5697\n",
            "Epoch 116/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2411 - accuracy: 0.5635 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 117/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2475 - accuracy: 0.5612 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 118/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2499 - accuracy: 0.5595 - val_loss: 1.2381 - val_accuracy: 0.5697\n",
            "Epoch 119/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2424 - accuracy: 0.5659 - val_loss: 1.2388 - val_accuracy: 0.5697\n",
            "Epoch 120/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2424 - accuracy: 0.5644 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 121/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2419 - accuracy: 0.5647 - val_loss: 1.2385 - val_accuracy: 0.5697\n",
            "Epoch 122/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2404 - accuracy: 0.5658 - val_loss: 1.2378 - val_accuracy: 0.5697\n",
            "Epoch 123/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2455 - accuracy: 0.5640 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 124/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2448 - accuracy: 0.5652 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 125/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2481 - accuracy: 0.5606 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 126/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2543 - accuracy: 0.5575 - val_loss: 1.2381 - val_accuracy: 0.5697\n",
            "Epoch 127/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2408 - accuracy: 0.5645 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 128/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2444 - accuracy: 0.5633 - val_loss: 1.2394 - val_accuracy: 0.5697\n",
            "Epoch 129/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2415 - accuracy: 0.5644 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 130/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2451 - accuracy: 0.5613 - val_loss: 1.2391 - val_accuracy: 0.5697\n",
            "Epoch 131/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2453 - accuracy: 0.5625 - val_loss: 1.2388 - val_accuracy: 0.5697\n",
            "Epoch 132/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2464 - accuracy: 0.5631 - val_loss: 1.2381 - val_accuracy: 0.5697\n",
            "Epoch 133/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2458 - accuracy: 0.5605 - val_loss: 1.2382 - val_accuracy: 0.5697\n",
            "Epoch 134/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2467 - accuracy: 0.5627 - val_loss: 1.2384 - val_accuracy: 0.5697\n",
            "Epoch 135/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2438 - accuracy: 0.5621 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 136/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2480 - accuracy: 0.5617 - val_loss: 1.2406 - val_accuracy: 0.5697\n",
            "Epoch 137/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2451 - accuracy: 0.5617 - val_loss: 1.2384 - val_accuracy: 0.5697\n",
            "Epoch 138/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2449 - accuracy: 0.5643 - val_loss: 1.2382 - val_accuracy: 0.5697\n",
            "Epoch 139/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2435 - accuracy: 0.5633 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 140/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2445 - accuracy: 0.5642 - val_loss: 1.2396 - val_accuracy: 0.5697\n",
            "Epoch 141/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2467 - accuracy: 0.5598 - val_loss: 1.2388 - val_accuracy: 0.5697\n",
            "Epoch 142/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2428 - accuracy: 0.5635 - val_loss: 1.2392 - val_accuracy: 0.5697\n",
            "Epoch 143/150\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 1.2417 - accuracy: 0.5645 - val_loss: 1.2382 - val_accuracy: 0.5697\n",
            "Epoch 144/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2467 - accuracy: 0.5630 - val_loss: 1.2379 - val_accuracy: 0.5697\n",
            "Epoch 145/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2468 - accuracy: 0.5602 - val_loss: 1.2390 - val_accuracy: 0.5697\n",
            "Epoch 146/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2505 - accuracy: 0.5604 - val_loss: 1.2389 - val_accuracy: 0.5697\n",
            "Epoch 147/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2461 - accuracy: 0.5621 - val_loss: 1.2384 - val_accuracy: 0.5697\n",
            "Epoch 148/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2423 - accuracy: 0.5645 - val_loss: 1.2385 - val_accuracy: 0.5697\n",
            "Epoch 149/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2415 - accuracy: 0.5638 - val_loss: 1.2386 - val_accuracy: 0.5697\n",
            "Epoch 150/150\n",
            "357/357 [==============================] - 1s 3ms/step - loss: 1.2455 - accuracy: 0.5624 - val_loss: 1.2387 - val_accuracy: 0.5697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DSbYY5VZode"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_NN = classifier.predict(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hij1bcrUusaC"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qZitZoJvPEz"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwpJsLYpuyYH"
      },
      "source": [
        "Word2vec One_hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxlIGFRiuvS7"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "\n",
        "#use onehot in train\n",
        "voc_size = 1000\n",
        "\n",
        "train_onehot = [one_hot(words, voc_size)for words in train['text']]\n",
        "dev_onehot = [one_hot(words, voc_size)for words in dev['text']]\n",
        "test_onehot = [one_hot(words, voc_size)for words in test['text']]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6knphhAu4aR"
      },
      "source": [
        "#performing pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sent_length=20\n",
        "embedded_train=pad_sequences(train_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_dev=pad_sequences(dev_onehot,padding='pre',maxlen=sent_length)\n",
        "embedded_test = pad_sequences(test_onehot,padding='pre',maxlen=sent_length)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-isMsvRJkn-"
      },
      "source": [
        "#spliting datas for training\n",
        "train['category_category'] = pd.Categorical(train['category'])\n",
        "\n",
        "X_train = np.array(embedded_train)\n",
        "y_train = np.array(train['category'])\n",
        "\n",
        "X_dev =  np.array(embedded_dev)\n",
        "y_dev = np.array(dev['category'])\n",
        "\n",
        "X_test =  np.array(embedded_test)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uHTb5XQu4Uw",
        "outputId": "2aeda6e2-650e-4dc6-a27e-8ba4d702a4e9"
      },
      "source": [
        "dim=40\n",
        "model=Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "#input layer\n",
        "#model.add(LSTM(100)\n",
        "model.add(LSTM(1000, input_shape=(1000,1), return_sequences=False))\n",
        "#hidded layer\n",
        "model.add(Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01), ))\n",
        "#output layer\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile('adam','mse')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBZ37Z-DvChh",
        "outputId": "62be3a53-9186-4142-b94a-a6de00e202d3"
      },
      "source": [
        "#summary of LSTM model\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 20, 40)            40000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000)              4164000   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 4,707,005\n",
            "Trainable params: 4,707,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyyW9BEYvISE",
        "outputId": "81aa867c-20e9-49b1-f851-06fe7bd3e301"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=64,\n",
        "                    epochs=50, validation_data=(X_dev, y_dev)                 \n",
        "                    )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "558/558 [==============================] - 24s 39ms/step - loss: 2.1520 - accuracy: 0.5552 - val_loss: 1.1581 - val_accuracy: 0.5727\n",
            "Epoch 2/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.1162 - accuracy: 0.5766 - val_loss: 1.1205 - val_accuracy: 0.5835\n",
            "Epoch 3/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.0788 - accuracy: 0.5894 - val_loss: 1.0923 - val_accuracy: 0.5868\n",
            "Epoch 4/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.0452 - accuracy: 0.5980 - val_loss: 1.0831 - val_accuracy: 0.5891\n",
            "Epoch 5/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.0318 - accuracy: 0.6012 - val_loss: 1.0870 - val_accuracy: 0.5810\n",
            "Epoch 6/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.0103 - accuracy: 0.6123 - val_loss: 1.0922 - val_accuracy: 0.5760\n",
            "Epoch 7/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 1.0083 - accuracy: 0.6146 - val_loss: 1.0773 - val_accuracy: 0.5891\n",
            "Epoch 8/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.9850 - accuracy: 0.6251 - val_loss: 1.0767 - val_accuracy: 0.5893\n",
            "Epoch 9/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.9692 - accuracy: 0.6337 - val_loss: 1.0987 - val_accuracy: 0.5810\n",
            "Epoch 10/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.9535 - accuracy: 0.6354 - val_loss: 1.1177 - val_accuracy: 0.5772\n",
            "Epoch 11/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.9371 - accuracy: 0.6473 - val_loss: 1.1168 - val_accuracy: 0.5830\n",
            "Epoch 12/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.9174 - accuracy: 0.6585 - val_loss: 1.1357 - val_accuracy: 0.5828\n",
            "Epoch 13/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.8899 - accuracy: 0.6679 - val_loss: 1.1578 - val_accuracy: 0.5689\n",
            "Epoch 14/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.8533 - accuracy: 0.6903 - val_loss: 1.1953 - val_accuracy: 0.5482\n",
            "Epoch 15/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.8092 - accuracy: 0.7067 - val_loss: 1.2636 - val_accuracy: 0.5560\n",
            "Epoch 16/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.7661 - accuracy: 0.7288 - val_loss: 1.3012 - val_accuracy: 0.5475\n",
            "Epoch 17/50\n",
            "558/558 [==============================] - 22s 39ms/step - loss: 0.7062 - accuracy: 0.7562 - val_loss: 1.4344 - val_accuracy: 0.5295\n",
            "Epoch 18/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.6234 - accuracy: 0.7904 - val_loss: 1.5816 - val_accuracy: 0.5522\n",
            "Epoch 19/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.5419 - accuracy: 0.8251 - val_loss: 1.6673 - val_accuracy: 0.5255\n",
            "Epoch 20/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.4495 - accuracy: 0.8632 - val_loss: 1.8772 - val_accuracy: 0.5020\n",
            "Epoch 21/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.3774 - accuracy: 0.8917 - val_loss: 2.0752 - val_accuracy: 0.5209\n",
            "Epoch 22/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.2941 - accuracy: 0.9225 - val_loss: 2.2715 - val_accuracy: 0.5028\n",
            "Epoch 23/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.2621 - accuracy: 0.9338 - val_loss: 2.4890 - val_accuracy: 0.5106\n",
            "Epoch 24/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.2015 - accuracy: 0.9562 - val_loss: 2.5821 - val_accuracy: 0.5169\n",
            "Epoch 25/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1822 - accuracy: 0.9617 - val_loss: 2.7510 - val_accuracy: 0.5035\n",
            "Epoch 26/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1550 - accuracy: 0.9727 - val_loss: 2.7832 - val_accuracy: 0.5073\n",
            "Epoch 27/50\n",
            "558/558 [==============================] - 22s 39ms/step - loss: 0.1484 - accuracy: 0.9731 - val_loss: 3.0058 - val_accuracy: 0.4932\n",
            "Epoch 28/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1223 - accuracy: 0.9799 - val_loss: 3.0426 - val_accuracy: 0.4909\n",
            "Epoch 29/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1200 - accuracy: 0.9795 - val_loss: 3.1181 - val_accuracy: 0.5131\n",
            "Epoch 30/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1112 - accuracy: 0.9820 - val_loss: 3.2795 - val_accuracy: 0.5010\n",
            "Epoch 31/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1110 - accuracy: 0.9823 - val_loss: 3.1852 - val_accuracy: 0.5111\n",
            "Epoch 32/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1099 - accuracy: 0.9823 - val_loss: 3.1250 - val_accuracy: 0.5045\n",
            "Epoch 33/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0863 - accuracy: 0.9883 - val_loss: 3.3062 - val_accuracy: 0.5048\n",
            "Epoch 34/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1115 - accuracy: 0.9817 - val_loss: 3.2360 - val_accuracy: 0.5030\n",
            "Epoch 35/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0837 - accuracy: 0.9882 - val_loss: 3.4350 - val_accuracy: 0.5174\n",
            "Epoch 36/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0714 - accuracy: 0.9912 - val_loss: 3.5666 - val_accuracy: 0.5141\n",
            "Epoch 37/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0648 - accuracy: 0.9922 - val_loss: 3.7308 - val_accuracy: 0.5109\n",
            "Epoch 38/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1528 - accuracy: 0.9734 - val_loss: 3.1989 - val_accuracy: 0.5204\n",
            "Epoch 39/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0864 - accuracy: 0.9865 - val_loss: 3.6191 - val_accuracy: 0.5144\n",
            "Epoch 40/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0694 - accuracy: 0.9909 - val_loss: 3.4281 - val_accuracy: 0.5139\n",
            "Epoch 41/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0726 - accuracy: 0.9905 - val_loss: 3.4023 - val_accuracy: 0.5154\n",
            "Epoch 42/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0897 - accuracy: 0.9856 - val_loss: 3.5613 - val_accuracy: 0.5121\n",
            "Epoch 43/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0847 - accuracy: 0.9875 - val_loss: 3.4825 - val_accuracy: 0.5220\n",
            "Epoch 44/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0643 - accuracy: 0.9912 - val_loss: 3.6169 - val_accuracy: 0.5081\n",
            "Epoch 45/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0557 - accuracy: 0.9931 - val_loss: 3.5343 - val_accuracy: 0.5305\n",
            "Epoch 46/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0763 - accuracy: 0.9886 - val_loss: 3.5875 - val_accuracy: 0.5220\n",
            "Epoch 47/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.1330 - accuracy: 0.9757 - val_loss: 3.2065 - val_accuracy: 0.5083\n",
            "Epoch 48/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0651 - accuracy: 0.9902 - val_loss: 3.2996 - val_accuracy: 0.5083\n",
            "Epoch 49/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0432 - accuracy: 0.9955 - val_loss: 3.1848 - val_accuracy: 0.5005\n",
            "Epoch 50/50\n",
            "558/558 [==============================] - 21s 38ms/step - loss: 0.0405 - accuracy: 0.9956 - val_loss: 3.2410 - val_accuracy: 0.5308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbCrdLjbeBbF"
      },
      "source": [
        "#classified with test set\n",
        "y_pred_test_LSTM = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}